{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1db3240",
   "metadata": {},
   "source": [
    "# Algorithmic Macronizer\n",
    "\n",
    "Testa mapp med 15 om-makroniserade Norma-texter. De saknar [] och {}, så dessa måste ignoreras. Vi testar i lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e162b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'norma-syllabarum-graecarum/final'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m s.replace(\u001b[33m\"\u001b[39m\u001b[33m^\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# iterate over all files in gold folder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgold_versions\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fname.endswith(\u001b[33m\"\u001b[39m\u001b[33m.txt\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     31\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'norma-syllabarum-graecarum/final'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from grc_utils import lower_grc, normalize_word\n",
    "\n",
    "chars_to_clean = r'[()\\[\\]{}<>⟨⟩⎡⎤\\\"«»\\-—…|⏑⏓†×]'\n",
    "\n",
    "macronizer_versions = \"norma_macronizer\"\n",
    "gold_versions = \"norma-syllabarum-graecarum/final\"\n",
    "\n",
    "# global counters\n",
    "short_total_global = 0\n",
    "long_total_global = 0\n",
    "short_fails_global = 0\n",
    "long_fails_global = 0\n",
    "line_total_global = 0\n",
    "line_matches_global = 0\n",
    "\n",
    "def clean_line(line):\n",
    "    line = lower_grc(line)\n",
    "    line = normalize_word(line)\n",
    "    line = re.sub(chars_to_clean, \"\", line)\n",
    "    return line.strip()\n",
    "\n",
    "def strip_markers(s):\n",
    "    \"\"\"Remove ^ and _ for comparison of base text.\"\"\"\n",
    "    return s.replace(\"^\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "# iterate over all files in gold folder\n",
    "for fname in os.listdir(gold_versions):\n",
    "    if not fname.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    gold_path = os.path.join(gold_versions, fname)\n",
    "    macronizer_path = os.path.join(macronizer_versions, fname)\n",
    "\n",
    "    if not os.path.exists(macronizer_path):\n",
    "        print(f\"Skipping {fname}: no matching macronizer file.\")\n",
    "        continue\n",
    "\n",
    "    with open(gold_path, encoding=\"utf-8\") as g, open(macronizer_path, encoding=\"utf-8\") as m:\n",
    "        gold_lines = [clean_line(l) for l in g if l.strip()]\n",
    "        macronizer_lines = [clean_line(l) for l in m if l.strip()]\n",
    "\n",
    "    # per-file counters\n",
    "    short_total = 0\n",
    "    long_total = 0\n",
    "    short_fails = 0\n",
    "    long_fails = 0\n",
    "    line_total = 0\n",
    "    line_matches = 0\n",
    "\n",
    "    # safeguard: iterate over min length\n",
    "    for gold_line, macron_line in zip(gold_lines, macronizer_lines):\n",
    "        gi = len(gold_line) - 1\n",
    "        mi = len(macron_line) - 1\n",
    "\n",
    "        # line-level match ignoring ^_\n",
    "        line_total += 1\n",
    "        if strip_markers(gold_line) == strip_markers(macron_line):\n",
    "            line_matches += 1\n",
    "\n",
    "        while gi >= 0:\n",
    "            gch = gold_line[gi]\n",
    "\n",
    "            if gch == \"^\":\n",
    "                short_total += 1\n",
    "                if mi < 0:\n",
    "                    # nothing left in macronizer → assume default short, no fail\n",
    "                    pass\n",
    "                elif macron_line[mi] == \"^\":\n",
    "                    mi -= 1  # matched short\n",
    "                elif macron_line[mi] == \"_\":\n",
    "                    short_fails += 1  # explicit contradiction\n",
    "                    mi -= 1\n",
    "                else:\n",
    "                    # neither ^ nor _ → treat as implicit short, no fail\n",
    "                    mi -= 1\n",
    "\n",
    "            elif gch == \"_\":\n",
    "                long_total += 1\n",
    "                if mi < 0 or macron_line[mi] != \"_\":\n",
    "                    long_fails += 1\n",
    "                else:\n",
    "                    mi -= 1  # matched long\n",
    "\n",
    "            else:\n",
    "                mi -= 1  # advance only on real characters\n",
    "\n",
    "            gi -= 1\n",
    "\n",
    "    # update globals\n",
    "    short_total_global += short_total\n",
    "    long_total_global += long_total\n",
    "    short_fails_global += short_fails\n",
    "    long_fails_global += long_fails\n",
    "    line_total_global += line_total\n",
    "    line_matches_global += line_matches\n",
    "\n",
    "    # per-file report\n",
    "    short_success = short_total - short_fails\n",
    "    long_success = long_total - long_fails\n",
    "    both_total = short_total + long_total\n",
    "    both_success = short_success + long_success\n",
    "\n",
    "    print(f\"\\n=== File: {fname} ===\")\n",
    "    if short_total:\n",
    "        print(f\"^ success: {short_success}/{short_total} = {short_success/short_total:.4f}\")\n",
    "    if long_total:\n",
    "        print(f\"_ success: {long_success}/{long_total} = {long_success/long_total:.4f}\")\n",
    "    if both_total:\n",
    "        print(f\"Both success: {both_success}/{both_total} = {both_success/both_total:.4f}\")\n",
    "    if line_total:\n",
    "        print(f\"Line matches ignoring ^_: {line_matches}/{line_total} = {line_matches/line_total:.4f}\")\n",
    "\n",
    "# global summary\n",
    "short_success_global = short_total_global - short_fails_global\n",
    "long_success_global = long_total_global - long_fails_global\n",
    "both_total_global = short_total_global + long_total_global\n",
    "both_success_global = short_success_global + long_success_global\n",
    "\n",
    "print(\"\\n=== Global summary ===\")\n",
    "if short_total_global:\n",
    "    print(f\"^ success: {short_success_global}/{short_total_global} = {short_success_global/short_total_global:.4f}\")\n",
    "if long_total_global:\n",
    "    print(f\"_ success: {long_success_global}/{long_total_global} = {long_success_global/long_total_global:.4f}\")\n",
    "if both_total_global:\n",
    "    print(f\"Both success: {both_success_global}/{both_total_global} = {both_success_global/both_total_global:.4f}\")\n",
    "if line_total_global:\n",
    "    print(f\"Line matches ignoring ^_: {line_matches_global}/{line_total_global} = {line_matches_global/line_total_global:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
